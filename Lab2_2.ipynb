{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YouJoohyung/myfirst-project/blob/0607_%EC%9E%A5%EB%B3%91%ED%83%81pf/Lab2_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sbkFbNUAKyK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose,ToTensor\n",
        "\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK2GCy6Bmpiy",
        "outputId": "7769fded-7e9d-491b-a58a-2e7a229abbbd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-mCz91mryvd"
      },
      "source": [
        "#### Connect to local google drive & settings for export/import models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_1Cr9tsrydl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cbd23ad-9d30-4db3-b848-85213fec8d91"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "!mkdir ./gdrive/'My Drive'/MNIST_models/"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "mkdir: cannot create directory ‘./gdrive/My Drive/MNIST_models/’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2nLnUERGaL_"
      },
      "source": [
        "#### DNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV9KcFU1FKsR"
      },
      "source": [
        "class MNISTDNN(nn.Module):\n",
        "    def __init__(self,IMG_SIZE=28):\n",
        "        super(MNISTDNN,self).__init__()\n",
        "        self.fc1 = nn.Linear(IMG_SIZE*IMG_SIZE,32)\n",
        "        self.BN1 = torch.nn.BatchNorm1d(32)\n",
        "        self.fc2 = nn.Linear(32,10)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.BN1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.softmax(x,dim=-1)\n",
        "        return x    "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNCKxXJwGdN4"
      },
      "source": [
        "#### CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvofB0pnGfHM"
      },
      "source": [
        "class MNISTCNN(nn.Module):\n",
        "    def __init__(self,IMG_SIZE=28):\n",
        "        super(MNISTCNN,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,8,5,stride=2)\n",
        "        self.BN1 = torch.nn.BatchNorm2d(8)\n",
        "        self.conv2 = nn.Conv2d(8,8,5,stride=2)\n",
        "        self.BN2 = torch.nn.BatchNorm2d(8)\n",
        "        self.conv3 = nn.Conv2d(8,8,3,stride=1)\n",
        "        self.fc = nn.Linear(8*2*2,10)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.BN1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.BN2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = x.view(-1,8*2*2)\n",
        "        x = self.fc(x)\n",
        "        x = torch.softmax(x,dim=-1)\n",
        "        return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zyvh6IKYZcdi"
      },
      "source": [
        "#### Util function for calculating accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YSzoolPQqIL"
      },
      "source": [
        "def compute_acc(argmax,y):\n",
        "    count = 0\n",
        "    for i in range(len(argmax)):\n",
        "        if argmax[i]==y[i]:\n",
        "            count+=1\n",
        "    return count / len(argmax)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7KNrp6hGXWI"
      },
      "source": [
        "#### hyperparameters & datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vny-hSnYGOx5"
      },
      "source": [
        "IMG_SIZE = 28\n",
        "BATCH_SIZE = 256\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHES = 30"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpnCYlVHBuSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d596e1d1-e132-4917-f51a-37a2fb870284"
      },
      "source": [
        "transforms = Compose([\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "trainset = MNIST('/content/gdrive/MyDrive/MNIST_models/',train=True,transform=transforms,download=True)\n",
        "testset = MNIST('/content/gdrive/MyDrive/MNIST_models/',train=False,transform=transforms,download=True)\n",
        "\n",
        "args = {\n",
        "    'num_workers' : 1,\n",
        "    'batch_size' : BATCH_SIZE,\n",
        "    'shuffle' : True,\n",
        "}\n",
        "\n",
        "train_loader = DataLoader(trainset,**args)\n",
        "test_loader = DataLoader(testset,**args)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/gdrive/MyDrive/MNIST_models/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 176320680.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/gdrive/MyDrive/MNIST_models/MNIST/raw/train-images-idx3-ubyte.gz to /content/gdrive/MyDrive/MNIST_models/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/gdrive/MyDrive/MNIST_models/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 154312985.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/gdrive/MyDrive/MNIST_models/MNIST/raw/train-labels-idx1-ubyte.gz to /content/gdrive/MyDrive/MNIST_models/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/gdrive/MyDrive/MNIST_models/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 88070235.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/gdrive/MyDrive/MNIST_models/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/gdrive/MyDrive/MNIST_models/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/gdrive/MyDrive/MNIST_models/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7687864.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/gdrive/MyDrive/MNIST_models/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/gdrive/MyDrive/MNIST_models/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw9IBUpYZPqb"
      },
      "source": [
        "####Training part(DNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPSsZM0uGs2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0de619-820e-439e-abf7-241d665ffa5b"
      },
      "source": [
        "model = MNISTDNN(IMG_SIZE).cuda()\n",
        "\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(\"number of parameters : {}\".format(num_params))\n",
        "\n",
        "optimizer = Adam(model.parameters(),lr=LEARNING_RATE)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(NUM_EPOCHES):\n",
        "    tot_loss = 0.0\n",
        "    \n",
        "    for x,y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "        y_ = model(x)\n",
        "        loss = loss_fn(y_, y.cuda())\n",
        "        loss.backward()\n",
        "        tot_loss+=loss.item()\n",
        "        optimizer.step()\n",
        "        \n",
        "    print(\"Epoch {}, Loss(train) : {}\".format(epoch+1,tot_loss))\n",
        "    if epoch % 2 == 1:\n",
        "        x,y = next(iter(test_loader))\n",
        "        x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "        y_ = model(x)\n",
        "        _, argmax = torch.max(y_,dim=-1)\n",
        "        test_acc = compute_acc(argmax,y.numpy())\n",
        "        \n",
        "        print(\"Acc(val) : {}\".format(test_acc))\n",
        "\n",
        "torch.save(model.state_dict(), \"/content/gdrive/My Drive/MNIST_models/DNN.pt\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters : 25514\n",
            "Epoch 1, Loss(train) : 407.6065183877945\n",
            "Epoch 2, Loss(train) : 368.231654047966\n",
            "Acc(val) : 0.9296875\n",
            "Epoch 3, Loss(train) : 361.77316319942474\n",
            "Epoch 4, Loss(train) : 358.40818321704865\n",
            "Acc(val) : 0.9609375\n",
            "Epoch 5, Loss(train) : 356.22821593284607\n",
            "Epoch 6, Loss(train) : 354.5317679643631\n",
            "Acc(val) : 0.96484375\n",
            "Epoch 7, Loss(train) : 353.2864907979965\n",
            "Epoch 8, Loss(train) : 352.3718651533127\n",
            "Acc(val) : 0.96875\n",
            "Epoch 9, Loss(train) : 351.6593829393387\n",
            "Epoch 10, Loss(train) : 350.9839265346527\n",
            "Acc(val) : 0.95703125\n",
            "Epoch 11, Loss(train) : 350.51428508758545\n",
            "Epoch 12, Loss(train) : 349.9280000925064\n",
            "Acc(val) : 0.9609375\n",
            "Epoch 13, Loss(train) : 349.71957993507385\n",
            "Epoch 14, Loss(train) : 349.4683338403702\n",
            "Acc(val) : 0.94921875\n",
            "Epoch 15, Loss(train) : 349.0863035917282\n",
            "Epoch 16, Loss(train) : 348.7412737607956\n",
            "Acc(val) : 0.9765625\n",
            "Epoch 17, Loss(train) : 348.631089925766\n",
            "Epoch 18, Loss(train) : 348.3083356618881\n",
            "Acc(val) : 0.96875\n",
            "Epoch 19, Loss(train) : 348.16791689395905\n",
            "Epoch 20, Loss(train) : 348.06516695022583\n",
            "Acc(val) : 0.9609375\n",
            "Epoch 21, Loss(train) : 347.9045263528824\n",
            "Epoch 22, Loss(train) : 347.6885714530945\n",
            "Acc(val) : 0.95703125\n",
            "Epoch 23, Loss(train) : 347.5676292181015\n",
            "Epoch 24, Loss(train) : 347.5039623975754\n",
            "Acc(val) : 0.97265625\n",
            "Epoch 25, Loss(train) : 347.4709075689316\n",
            "Epoch 26, Loss(train) : 347.3011198043823\n",
            "Acc(val) : 0.97265625\n",
            "Epoch 27, Loss(train) : 347.39475405216217\n",
            "Epoch 28, Loss(train) : 347.0614603757858\n",
            "Acc(val) : 0.95703125\n",
            "Epoch 29, Loss(train) : 347.0285748243332\n",
            "Epoch 30, Loss(train) : 346.960223197937\n",
            "Acc(val) : 0.97265625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyC_PAFPMPLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63c0d1e-cb7d-447e-fb25-570bf22b2081"
      },
      "source": [
        "model_test = MNISTDNN(IMG_SIZE).cuda()\n",
        "model_test.load_state_dict(torch.load(\"/content/gdrive/My Drive/MNIST_models/DNN.pt\"))\n",
        "model_test.eval()\n",
        "x,y = next(iter(test_loader))\n",
        "x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "y_ = model_test(x)\n",
        "_, argmax = torch.max(y_,dim=-1)\n",
        "test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "print(\"Acc(test) : {}\".format(test_acc))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc(test) : 0.98046875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZlMbw_tZLT-"
      },
      "source": [
        "#### Training part(CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_hp82IXWJ4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf0bab1e-93dc-4e16-d71e-d030af4ff372"
      },
      "source": [
        "model = MNISTCNN(IMG_SIZE).cuda()\n",
        "\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(\"number of parameters : {}\".format(num_params))\n",
        "\n",
        "optimizer = Adam(model.parameters(),lr=LEARNING_RATE)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(NUM_EPOCHES):\n",
        "    tot_loss = 0.0\n",
        "    \n",
        "    for x,y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        x = x.cuda()\n",
        "        y_ = model(x)\n",
        "        loss = loss_fn(y_, y.cuda())\n",
        "        loss.backward()\n",
        "        tot_loss+=loss.item()\n",
        "        optimizer.step()\n",
        "        \n",
        "    print(\"Epoch {}, Loss(train) : {}\".format(epoch+1,tot_loss))\n",
        "    if epoch % 2 == 1:\n",
        "        model.eval()\n",
        "        \n",
        "        x,y = next(iter(test_loader))\n",
        "        x = x.cuda()\n",
        "        y_ = model(x)\n",
        "        _, argmax = torch.max(y_,dim=-1)\n",
        "        test_acc = compute_acc(argmax,y.numpy())\n",
        "        \n",
        "        print(\"Acc(test) : {}\".format(test_acc))\n",
        "        \n",
        "        model.train()\n",
        "\n",
        "torch.save(model.state_dict(), \"/content/gdrive/My Drive/MNIST_models/CNN.pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters : 2762\n",
            "Epoch 1, Loss(train) : 431.99150371551514\n",
            "Epoch 2, Loss(train) : 365.27305698394775\n",
            "Acc(test) : 0.94140625\n",
            "Epoch 3, Loss(train) : 358.12150156497955\n",
            "Epoch 4, Loss(train) : 355.04672944545746\n",
            "Acc(test) : 0.97265625\n",
            "Epoch 5, Loss(train) : 353.2219293117523\n",
            "Epoch 6, Loss(train) : 352.014816403389\n",
            "Acc(test) : 0.9609375\n",
            "Epoch 7, Loss(train) : 351.14613676071167\n",
            "Epoch 8, Loss(train) : 350.4977465867996\n",
            "Acc(test) : 0.97265625\n",
            "Epoch 9, Loss(train) : 350.0155040025711\n",
            "Epoch 10, Loss(train) : 349.5600552558899\n",
            "Acc(test) : 0.9921875\n",
            "Epoch 11, Loss(train) : 349.28144812583923\n",
            "Epoch 12, Loss(train) : 348.8999457359314\n",
            "Acc(test) : 0.984375\n",
            "Epoch 13, Loss(train) : 348.7143303155899\n",
            "Epoch 14, Loss(train) : 348.36587512493134\n",
            "Acc(test) : 0.98828125\n",
            "Epoch 15, Loss(train) : 348.1851484775543\n",
            "Epoch 16, Loss(train) : 348.1170176267624\n",
            "Acc(test) : 0.9765625\n",
            "Epoch 17, Loss(train) : 347.8389639854431\n",
            "Epoch 18, Loss(train) : 347.79782915115356\n",
            "Acc(test) : 0.9765625\n",
            "Epoch 19, Loss(train) : 347.66490614414215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xhN_wmbMR41"
      },
      "source": [
        "model_test = MNISTCNN(IMG_SIZE).cuda()\n",
        "model_test.load_state_dict(torch.load(\"/content/gdrive/My Drive/MNIST_models/CNN.pt\"))\n",
        "model_test.eval()\n",
        "x,y = next(iter(test_loader))\n",
        "x = x.cuda()\n",
        "y_ = model_test(x)\n",
        "_, argmax = torch.max(y_,dim=-1)\n",
        "test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "print(\"Acc(test) : {}\".format(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSMsL5fKVONu"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}